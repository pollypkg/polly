{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! \u00b6 Polly is a specification for parameterized packages of observability-related configuration objects such as dashboards, alerts and more . With polly packages we intend to address the fundamental challenges involved in keeping observability systems in sync with the systems they're intended to observe, addressing question including but not limited to: Who creates and maintains these objects? Who knows enough to do it? To do it well? For OSS systems we didn't write ourselves? How can we be sure these objects are the right ones for the versions of our systems? How can we define common properties, invariants, or aggregations over these objects across an entire organization? When the organization's telemetry data is heterogenous? We see the full lifecycle these configuration objects as within scope of polly. In our repo you will find the polly specification and the rest of the documentation is on this site. And now: go and give it a try by visiting the usage section or check out the community section to learn more about he vision and how to start contributing.","title":"Welcome!"},{"location":"#welcome","text":"Polly is a specification for parameterized packages of observability-related configuration objects such as dashboards, alerts and more . With polly packages we intend to address the fundamental challenges involved in keeping observability systems in sync with the systems they're intended to observe, addressing question including but not limited to: Who creates and maintains these objects? Who knows enough to do it? To do it well? For OSS systems we didn't write ourselves? How can we be sure these objects are the right ones for the versions of our systems? How can we define common properties, invariants, or aggregations over these objects across an entire organization? When the organization's telemetry data is heterogenous? We see the full lifecycle these configuration objects as within scope of polly. In our repo you will find the polly specification and the rest of the documentation is on this site. And now: go and give it a try by visiting the usage section or check out the community section to learn more about he vision and how to start contributing.","title":"Welcome!"},{"location":"about/","text":"About \u00b6 With polly, we're building on the shoulder of giants, or in other words: this is not the first attempt to make observability tooling templating work. It all started out in 04/2018 with Frederic Branczyk proposing Jsonnet Package Management which was further on adopted in several places such as Prometheus Monitoring Mixins which had the tagline: A mixin is a set of Grafana dashboards and Prometheus rules and alerts, packaged together in a reuseable and extensible bundle. Mixins are written in jsonnet, and are typically installed and updated with jsonnet-bundler. The Mixins, based on jsonnet and maintained alongside the tool turned out to be a great idea, however, over time certain challenges and limitations became apparent. These shortcomings led to a desire to improve on the existing work on Mixins, resulting in what we now know as polly. Initially simply called Mixins-NG (next generation), the work around polly kicked off publicly in April 2021 , with Sam Boyer's mail to the newly created Mixins mailing list. At that point, sam already had been working on the concept and core formalization for several months, broadening the group of folks involved, initially a small group of interested folks, a mixture of past and future stakeholders and contributors to Mixins. At this point, polly doesn't have a formal governance body or rule set, but we do have: A guide on how to contribute to polly. The commitment that polly and the artifacts in the organization are available under Apache License Version 2.0 and will continue to be so. For any questions or suggestions, we ask you to use the polly project discussion section in the main repo. sam, Matthias, Michael","title":"About"},{"location":"about/#about","text":"With polly, we're building on the shoulder of giants, or in other words: this is not the first attempt to make observability tooling templating work. It all started out in 04/2018 with Frederic Branczyk proposing Jsonnet Package Management which was further on adopted in several places such as Prometheus Monitoring Mixins which had the tagline: A mixin is a set of Grafana dashboards and Prometheus rules and alerts, packaged together in a reuseable and extensible bundle. Mixins are written in jsonnet, and are typically installed and updated with jsonnet-bundler. The Mixins, based on jsonnet and maintained alongside the tool turned out to be a great idea, however, over time certain challenges and limitations became apparent. These shortcomings led to a desire to improve on the existing work on Mixins, resulting in what we now know as polly. Initially simply called Mixins-NG (next generation), the work around polly kicked off publicly in April 2021 , with Sam Boyer's mail to the newly created Mixins mailing list. At that point, sam already had been working on the concept and core formalization for several months, broadening the group of folks involved, initially a small group of interested folks, a mixture of past and future stakeholders and contributors to Mixins. At this point, polly doesn't have a formal governance body or rule set, but we do have: A guide on how to contribute to polly. The commitment that polly and the artifacts in the organization are available under Apache License Version 2.0 and will continue to be so. For any questions or suggestions, we ask you to use the polly project discussion section in the main repo. sam, Matthias, Michael","title":"About"},{"location":"basics/","text":"Basic usage \u00b6 We have a very basic example in examples/basic/ that you can use to explore polly packages. This example contains multiple signals (in this case PromQL queries), a dataface, and in the end generates a Grafana dashboard with those lower level constructs. Prerequisites \u00b6 First you want to clone this repository to your local machine and then change into the repository's directory. Make sure to install CUE on your computer so you can run the cue command. Evaluating \u00b6 Because the example comes with parameterized parameters (params) we cannot straight export JSON or YAML, but instead can evaluate the example. This means that CUE will evaluate as much as possible of the end result, still leaving a few places without the final parameters/strings. From the root of the repository you can evaluate by running: cue eval ./examples/basic Note: If any of the constraints aren't fulfilled this step will fail and let you know that something is wrong. The output of the evaluation should look something along those lines: examplepkg: { header: { name: \"node-exporter\" uri: \"github.com/pollypkg/polly/examples/basic\" params: {} } signals: [{ name: \"NumCpu\" lang: \"promql\" params: { job: string instance: string } query: \"count without (cpu) (count without (mode) (node_cpu_seconds_total{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}))\" & string }, { name: \"MemoryUtilization\" lang: \"promql\" params: { job: string instance: string } query: \"1 - (node_memory_MemAvailable_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"} / node_memory_MemTotal_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"})\" & string }, { name: \"VmstatPGMajFault\" lang: \"promql\" params: { job: string instance: string } query: \"rate(node_vmstat_pgmajfault{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}[1m])\" & string }] datafaces: { use_mem: { name: \"USE\" frames: { utilization: \"MemoryUtilization\" saturation: \"VmstatPGMajFault\" errors: \"\" } } } grafanaDashboards: { v0: { nodedashboard: { uid: \"a8b327a\" style: \"light\" editable: true graphTooltip: 0 schemaVersion: 25 #Panel: { type: !=\"\" transparent: false repeatDirection: \"h\" options: {} fieldConfig: { defaults: {} overrides: [] } } } } } } Exporting \u00b6 To export you need to insert actual parameters to the polly package for it to be able to actually export real YAML. Let's give the example some concrete params: Note: directly modifying a polly package is NOT how we expect polly to be used in practice. Rather, you'll inject these parameter values via the tool that consumes the polly package. { name: \"NumCpu\" lang: \"promql\" - params: {job: string, instance: string} + params: {job: \"node\", instance: \"localhost:9100\"} query: \"count without (cpu) (count without (mode) (node_cpu_seconds_total{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}))\" }, // Amount of memory currently in use { name: \"MemoryUtilization\" lang: \"promql\" - params: {job: string, instance: string} + params: {job: \"node\", instance: \"localhost:9100\"} query: \"1 - (node_memory_MemAvailable_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"} / node_memory_MemTotal_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"})\" }, // One minute rate of major page faults { name: \"VmstatPGMajFault\" lang: \"promql\" - params: {job: string, instance: string} + params: {job: \"node\", instance: \"localhost:9100\"} query: \"rate(node_vmstat_pgmajfault{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}[1m])\" }, ] With that change, we can now run cue export ./examples/basic and will get a JSON output. Run cue export --out yaml ./examples/basic if you prefer YAML instead. The output of exporting looks like: examplepkg: header: name: node-exporter uri: github.com/pollypkg/polly/examples/basic params: {} signals: - name: NumCpu lang: promql params: job: node instance: localhost:9100 query: count without (cpu) (count without (mode) (node_cpu_seconds_total{job=\"node\", instance=\"localhost:9100\"})) - name: MemoryUtilization lang: promql params: job: node instance: localhost:9100 query: 1 - (node_memory_MemAvailable_bytes{job=\"node\", instance=\"localhost:9100\"} / node_memory_MemTotal_bytes{job=\"node\", instance=\"localhost:9100\"}) - name: VmstatPGMajFault lang: promql params: job: node instance: localhost:9100 query: rate(node_vmstat_pgmajfault{job=\"node\", instance=\"localhost:9100\"}[1m]) datafaces: use_mem: name: USE frames: utilization: MemoryUtilization saturation: VmstatPGMajFault errors: \"\" grafanaDashboards: v0: nodedashboard: uid: a8b327a style: light editable: true graphTooltip: 0 schemaVersion: 25","title":"Basic usage"},{"location":"basics/#basic-usage","text":"We have a very basic example in examples/basic/ that you can use to explore polly packages. This example contains multiple signals (in this case PromQL queries), a dataface, and in the end generates a Grafana dashboard with those lower level constructs.","title":"Basic usage"},{"location":"basics/#prerequisites","text":"First you want to clone this repository to your local machine and then change into the repository's directory. Make sure to install CUE on your computer so you can run the cue command.","title":"Prerequisites"},{"location":"basics/#evaluating","text":"Because the example comes with parameterized parameters (params) we cannot straight export JSON or YAML, but instead can evaluate the example. This means that CUE will evaluate as much as possible of the end result, still leaving a few places without the final parameters/strings. From the root of the repository you can evaluate by running: cue eval ./examples/basic Note: If any of the constraints aren't fulfilled this step will fail and let you know that something is wrong. The output of the evaluation should look something along those lines: examplepkg: { header: { name: \"node-exporter\" uri: \"github.com/pollypkg/polly/examples/basic\" params: {} } signals: [{ name: \"NumCpu\" lang: \"promql\" params: { job: string instance: string } query: \"count without (cpu) (count without (mode) (node_cpu_seconds_total{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}))\" & string }, { name: \"MemoryUtilization\" lang: \"promql\" params: { job: string instance: string } query: \"1 - (node_memory_MemAvailable_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"} / node_memory_MemTotal_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"})\" & string }, { name: \"VmstatPGMajFault\" lang: \"promql\" params: { job: string instance: string } query: \"rate(node_vmstat_pgmajfault{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}[1m])\" & string }] datafaces: { use_mem: { name: \"USE\" frames: { utilization: \"MemoryUtilization\" saturation: \"VmstatPGMajFault\" errors: \"\" } } } grafanaDashboards: { v0: { nodedashboard: { uid: \"a8b327a\" style: \"light\" editable: true graphTooltip: 0 schemaVersion: 25 #Panel: { type: !=\"\" transparent: false repeatDirection: \"h\" options: {} fieldConfig: { defaults: {} overrides: [] } } } } } }","title":"Evaluating"},{"location":"basics/#exporting","text":"To export you need to insert actual parameters to the polly package for it to be able to actually export real YAML. Let's give the example some concrete params: Note: directly modifying a polly package is NOT how we expect polly to be used in practice. Rather, you'll inject these parameter values via the tool that consumes the polly package. { name: \"NumCpu\" lang: \"promql\" - params: {job: string, instance: string} + params: {job: \"node\", instance: \"localhost:9100\"} query: \"count without (cpu) (count without (mode) (node_cpu_seconds_total{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}))\" }, // Amount of memory currently in use { name: \"MemoryUtilization\" lang: \"promql\" - params: {job: string, instance: string} + params: {job: \"node\", instance: \"localhost:9100\"} query: \"1 - (node_memory_MemAvailable_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"} / node_memory_MemTotal_bytes{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"})\" }, // One minute rate of major page faults { name: \"VmstatPGMajFault\" lang: \"promql\" - params: {job: string, instance: string} + params: {job: \"node\", instance: \"localhost:9100\"} query: \"rate(node_vmstat_pgmajfault{job=\\\"\\(params.job)\\\", instance=\\\"\\(params.instance)\\\"}[1m])\" }, ] With that change, we can now run cue export ./examples/basic and will get a JSON output. Run cue export --out yaml ./examples/basic if you prefer YAML instead. The output of exporting looks like: examplepkg: header: name: node-exporter uri: github.com/pollypkg/polly/examples/basic params: {} signals: - name: NumCpu lang: promql params: job: node instance: localhost:9100 query: count without (cpu) (count without (mode) (node_cpu_seconds_total{job=\"node\", instance=\"localhost:9100\"})) - name: MemoryUtilization lang: promql params: job: node instance: localhost:9100 query: 1 - (node_memory_MemAvailable_bytes{job=\"node\", instance=\"localhost:9100\"} / node_memory_MemTotal_bytes{job=\"node\", instance=\"localhost:9100\"}) - name: VmstatPGMajFault lang: promql params: job: node instance: localhost:9100 query: rate(node_vmstat_pgmajfault{job=\"node\", instance=\"localhost:9100\"}[1m]) datafaces: use_mem: name: USE frames: utilization: MemoryUtilization saturation: VmstatPGMajFault errors: \"\" grafanaDashboards: v0: nodedashboard: uid: a8b327a style: light editable: true graphTooltip: 0 schemaVersion: 25","title":"Exporting"},{"location":"community/","text":"Community \u00b6 Learn about the polly packages lifecycle, our vision and how to contribute.","title":"Community"},{"location":"community/#community","text":"Learn about the polly packages lifecycle, our vision and how to contribute.","title":"Community"},{"location":"contrib/","text":"Contributing \u00b6 Discussions via GitHub Mailing list Slack: #monitoring-mixins channel on Kubernetes Slack","title":"Contributing"},{"location":"contrib/#contributing","text":"Discussions via GitHub Mailing list Slack: #monitoring-mixins channel on Kubernetes Slack","title":"Contributing"},{"location":"faq/","text":"FAQ \u00b6 Naming \u00b6 Question Why is it called polly? Answer The name \"Polly\" is a pseudo-acronym, loosely derived from (take your pick): * Parameterized (P) Observability (o11y) configuration packages * Packages (P) of Observability (o11y) configuration","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#naming","text":"Question Why is it called polly? Answer The name \"Polly\" is a pseudo-acronym, loosely derived from (take your pick): * Parameterized (P) Observability (o11y) configuration packages * Packages (P) of Observability (o11y) configuration","title":"Naming"},{"location":"lifecycle/","text":"Lifecycle \u00b6 This is where the contents of our GDocs goes: https://docs.google.com/document/d/1GU0DGy-X6z4FVwbJYPsBKRdqApi2RppW0q2U6YUXOp8","title":"Lifecycle"},{"location":"lifecycle/#lifecycle","text":"This is where the contents of our GDocs goes: https://docs.google.com/document/d/1GU0DGy-X6z4FVwbJYPsBKRdqApi2RppW0q2U6YUXOp8","title":"Lifecycle"},{"location":"usage/","text":"Usage \u00b6 Learn about how to use polly. For now, polly is mostly spec and we're adding support for tooling as we go. However, because a foundational goal of polly packages is to make observability universal - that is, avoiding lock-in to any particular deployment/devops toolchain - the tools provided here may be less featureful or useful than tools that fit polly packages into your existing toolchain (e.g. Terraform, jsonnet/Tanka, flux/2). We'll link to such tools as they evolve. We appreciate examples submissions, please follow the following guidelines: Explain what's the system under observation (SUO), for example a Kubernetes cluster or a VM or a database. If you show how to migrate from an existing mixin please link to it. Other questions to consider: What kind of parameters do you think it makes sense for your package to take? Why? How did you decide whether it was worth making particular queries into reusable signals? Which part of the polly spec was most confusing to work with? If you figured it out, what helped you get there? Is there anything about observing the SUO that the polly schema did not allow you to express in the pop? The PR should contain two parts: A dedicated directory under the examples directory that contains CUE code and any helpers and dependencies. A Markdown file under the docs content , you are encouraged to use basics.md as a starting point.","title":"Usage"},{"location":"usage/#usage","text":"Learn about how to use polly. For now, polly is mostly spec and we're adding support for tooling as we go. However, because a foundational goal of polly packages is to make observability universal - that is, avoiding lock-in to any particular deployment/devops toolchain - the tools provided here may be less featureful or useful than tools that fit polly packages into your existing toolchain (e.g. Terraform, jsonnet/Tanka, flux/2). We'll link to such tools as they evolve. We appreciate examples submissions, please follow the following guidelines: Explain what's the system under observation (SUO), for example a Kubernetes cluster or a VM or a database. If you show how to migrate from an existing mixin please link to it. Other questions to consider: What kind of parameters do you think it makes sense for your package to take? Why? How did you decide whether it was worth making particular queries into reusable signals? Which part of the polly spec was most confusing to work with? If you figured it out, what helped you get there? Is there anything about observing the SUO that the polly schema did not allow you to express in the pop? The PR should contain two parts: A dedicated directory under the examples directory that contains CUE code and any helpers and dependencies. A Markdown file under the docs content , you are encouraged to use basics.md as a starting point.","title":"Usage"},{"location":"vision/","text":"Vision \u00b6 All systems need observability. That starts with emitting telemetry data. But the raw data alone isn\u2019t enough. There\u2019s a set of steps - roughly: collect, transform, interpret, act - through which telemetry data passes that are necessary for software to be not merely observable, but observed by real, actual humans. These steps are performed by an observability platform, driven by the configuration of that platform. Of course, as software evolves, so too must the configuration that allows it to be observed. By nature, software and its observers are companions. Today\u2019s tooling, however, makes co-evolution of the two profoundly frictionful. That\u2019s what we\u2019re aiming to change - no matter how you ship software, your observability can ride sidecar. Achieving this has the potential to make observability go mainstream, much as testing has over the last decade.","title":"Vision"},{"location":"vision/#vision","text":"All systems need observability. That starts with emitting telemetry data. But the raw data alone isn\u2019t enough. There\u2019s a set of steps - roughly: collect, transform, interpret, act - through which telemetry data passes that are necessary for software to be not merely observable, but observed by real, actual humans. These steps are performed by an observability platform, driven by the configuration of that platform. Of course, as software evolves, so too must the configuration that allows it to be observed. By nature, software and its observers are companions. Today\u2019s tooling, however, makes co-evolution of the two profoundly frictionful. That\u2019s what we\u2019re aiming to change - no matter how you ship software, your observability can ride sidecar. Achieving this has the potential to make observability go mainstream, much as testing has over the last decade.","title":"Vision"}]}